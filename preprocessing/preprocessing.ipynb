{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb861e81-8564-4107-82cf-b14a07c4834a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Setting up Spark Session / Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_mb(size_bytes):\n",
    "    \"\"\"Converts bytes to megabytes.\"\"\"\n",
    "    return size_bytes / (1024 * 1024)\n",
    "\n",
    "def bytes_to_gb(size_bytes):\n",
    "    \"\"\"Converts bytes to gigabytes.\"\"\"\n",
    "    return size_bytes / (1024 * 1024 * 1024)\n",
    "\n",
    "def configure_spark(dataset_size_gb):\n",
    "    \"\"\"Configures Spark based on dataset size.\n",
    "\n",
    "    Args:\n",
    "        dataset_size_gb (float): Size of the dataset in gigabytes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Executor cores and memory configuration.\n",
    "    \"\"\"\n",
    "    if dataset_size_gb < 1:\n",
    "        executor_cores = 2\n",
    "        executor_memory = \"4g\"\n",
    "    elif 1 <= dataset_size_gb <= 10:\n",
    "        executor_cores = 4\n",
    "        executor_memory = \"8g\"\n",
    "    else:\n",
    "        executor_cores = 8\n",
    "        executor_memory = \"16g\"\n",
    "    return executor_cores, executor_memory\n",
    "\n",
    "\n",
    "def build_spark_session(hdfs_path, file_path, verbose=False):\n",
    "    \"\"\"Builds a Spark session and retrieves file size from HDFS.\n",
    "\n",
    "    Args:\n",
    "        hdfs_path (str): HDFS path.\n",
    "        file_path (str): File path within HDFS.\n",
    "        verbose (bool, optional): Enable verbose output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: SparkSession, SparkContext, and file size.\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.appName(\"Project Group 32 HDFSFileSize\").getOrCreate()\n",
    "    jvm = spark._jvm\n",
    "    conf = jvm.org.apache.hadoop.conf.Configuration()\n",
    "    fs = jvm.org.apache.hadoop.fs.FileSystem.get(jvm.java.net.URI.create(hdfs_path), conf)\n",
    "    path = jvm.org.apache.hadoop.fs.Path(file_path)\n",
    "    fileStatus = fs.getFileStatus(path)\n",
    "    fileSize = fileStatus.getLen()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"File size in bytes: {fileSize}\")\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "    executor_cores, executor_memory = configure_spark(bytes_to_gb(fileSize))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"A files size of {bytes_to_gb(fileSize):.4f} GB give spark executors with:\\n\"+\n",
    "            f\"Cores: {executor_cores}\\n\"+\n",
    "            f\"Mem/core: {int(executor_memory[:-1])/executor_cores:.0f}GB\")\n",
    "\n",
    "\n",
    "    spark_session = SparkSession.builder\\\n",
    "            .master(\"spark://192.168.2.156:7077\") \\\n",
    "            .appName(\"Project Group 32 Andreas\")\\\n",
    "            .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "            .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "            .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "            .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"60s\")\\\n",
    "            .config(\"spark.executor.cores\", executor_cores)\\\n",
    "            .config(\"spark.executor.memory\", executor_memory)\\\n",
    "            .config(\"spark.driver.port\",9999)\\\n",
    "            .config(\"spark.blockManager.port\",10005)\\\n",
    "            .getOrCreate()\n",
    "\n",
    "    # RDD API\n",
    "    spark_context = spark_session.sparkContext\n",
    "    spark_context.setLogLevel(\"ERROR\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Executor cores: {spark_session.conf.get('spark.executor.cores')}\")\n",
    "        print(f\"Executor memory: {spark_session.conf.get('spark.executor.memory')}\")\n",
    "\n",
    "    return spark_session, spark_context, fileSize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c388e54-f3ff-418e-865e-618c7194132f",
   "metadata": {},
   "source": [
    "## Create a dataframe to analyse the posts line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db317b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(spark_session, hdfs_path, file_path, fileSize, verbose=False):\n",
    "    \"\"\"Loads JSON data from HDFS into a Spark DataFrame.\n",
    "\n",
    "    Args:\n",
    "        spark_session (SparkSession): Spark session.\n",
    "        hdfs_path (str): HDFS path.\n",
    "        file_path (str): File path within HDFS.\n",
    "        fileSize (int): Size of the file in bytes.\n",
    "        verbose (bool, optional): Enable verbose output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Loaded Spark DataFrame.\n",
    "    \"\"\"\n",
    "    # Load JSON file into a Spark DataFrame\n",
    "    df = spark_session.read.json(hdfs_path + file_path)\n",
    "\n",
    "    if verbose:\n",
    "        # Count the number of partitions in the underlying RDD.\n",
    "        print(f\"Number of default partitions after loading the data: {df.rdd.getNumPartitions()}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Repartition using \"subreddit\" as key.\n",
    "    # The partition size matches the HDFS block size in MB.\n",
    "    no_partitions = math.ceil(bytes_to_mb(fileSize) / 128)\n",
    "    partition_key =  \"subreddit\"\n",
    "    df.repartition(no_partitions, partition_key)\n",
    "    if verbose:\n",
    "        print(f\"The data is now repartitoned on key: '{partition_key}', into {df.rdd.getNumPartitions()} partitions.\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Show schema to understand the structure\n",
    "        print(\"The schema:\")\n",
    "        df.printSchema()\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Show first few rows to inspect data\n",
    "        print(\"The first five entries in the dataframe:\")\n",
    "        df.show(5, truncate=False)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Count total number of rows\n",
    "        print(f\"Total Rows: {df.count()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682b100-d96f-4f0e-abe7-90d2a8bebb5c",
   "metadata": {},
   "source": [
    "## How many Subreddits do exist?\n",
    "\n",
    "-- We see that many post are not assigned to a Subreddit, since we want to train a Classification model, we delete the NULL post --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae10602-3066-4837-b87e-dbf81fae1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_and_split_data(df, seed=42, verbose=False):\n",
    "    \"\"\"Filters and splits the DataFrame into training and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame.\n",
    "        seed (int, optional): Random seed for splitting. Defaults to 42.\n",
    "        verbose (bool, optional): Enable verbose output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Training DataFrame, test DataFrame, and filtered data count.\n",
    "    \"\"\"\n",
    "    unique_subreddits = df.select(\"subreddit\").distinct().count()\n",
    "    if verbose:\n",
    "        print(f\"Unique Subreddits: {unique_subreddits}\")\n",
    "        df.groupBy(\"subreddit\").count().orderBy(col(\"count\").desc()).show(10, False)\n",
    "    else:\n",
    "        df.groupBy(\"subreddit\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "    # Filter out rows where subreddit is NULL\n",
    "    df_filtered = df.filter(col(\"subreddit\").isNotNull())\n",
    "\n",
    "    if verbose:\n",
    "        # Show first few rows after filtering\n",
    "        df_filtered.show(5, truncate=False)\n",
    "\n",
    "        # Count remaining rows\n",
    "        print(f\"Total Posts After Filtering: {df_filtered.count()}\")\n",
    "\n",
    "    # Filter out NULL subreddit, summary, or content\n",
    "    df_filtered = df.filter((col(\"subreddit\").isNotNull()) & (col(\"summary\").isNotNull()) & (col(\"content\").isNotNull()))\n",
    "\n",
    "    if verbose:\n",
    "        # Show filtered data\n",
    "        df_filtered.select(\"subreddit\", \"summary\", \"content\").show(5, truncate=False)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    train_data, test_data = df_filtered.randomSplit([0.8, 0.2], seed=seed)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Training set contains {train_data.count()} samples\\n\" +\n",
    "              f\"Test set contains {test_data.count()} samples.\")\n",
    "\n",
    "    return train_data, test_data, df_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595011a3-7885-4dea-ad15-a6224a8abf27",
   "metadata": {},
   "source": [
    "## To prepare the Data for our ML Classification Model, we use the columns summary and content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7ac53",
   "metadata": {},
   "source": [
    "## Create the training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a8547-ff5d-425d-8787-f5a06bc7933b",
   "metadata": {},
   "source": [
    "## We have to make the Text understandable for the algorithm\n",
    "\n",
    "1. We first tokenize the the columns\n",
    "2. Remove stop words, since they do not add information to the text\n",
    "3. We convert the Text with TF-IDF to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5d6e9-40b1-498d-b9c2-e48ed53478c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_pipe():\n",
    "    \"\"\"\n",
    "    Creates a pipeline for pre-processing text data for machine learning.\n",
    "\n",
    "    This pipeline includes tokenization, stop word removal, TF-IDF vectorization,\n",
    "    label indexing, and feature assembly.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Spark ML pipeline stages.\n",
    "    \"\"\"\n",
    "    # Tokenize summary and content\n",
    "    tokenizer  = Tokenizer(inputCol=\"summary\", outputCol=\"summary_tokens\")\n",
    "    tokenizer2 = Tokenizer(inputCol=\"content\", outputCol=\"content_tokens\")\n",
    "\n",
    "    # Remove stopwords\n",
    "    stopwords_remover  = StopWordsRemover(inputCol=\"summary_tokens\", outputCol=\"summary_clean\")\n",
    "    stopwords_remover2 = StopWordsRemover(inputCol=\"content_tokens\", outputCol=\"content_clean\")\n",
    "\n",
    "    # Convert words to numerical features using TF-IDF\n",
    "    hashing_tf = HashingTF(inputCol=\"summary_clean\", outputCol=\"summary_tf\", numFeatures=1000)\n",
    "    idf = IDF(inputCol=\"summary_tf\", outputCol=\"summary_features\")\n",
    "\n",
    "    hashing_tf2 = HashingTF(inputCol=\"content_clean\", outputCol=\"content_tf\", numFeatures=1000)\n",
    "    idf2 = IDF(inputCol=\"content_tf\", outputCol=\"content_features\")\n",
    "\n",
    "    # Convert subreddit (text label) into a numerical label\n",
    "    label_indexer = StringIndexer(inputCol=\"subreddit\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "    # Combine summary and content features\n",
    "    feature_assembler = VectorAssembler(inputCols=[\"summary_features\", \"content_features\"], outputCol=\"features\")\n",
    "\n",
    "    # Return pre-processing pipeline.\n",
    "    return [tokenizer, tokenizer2, stopwords_remover, stopwords_remover2,\n",
    "            hashing_tf, idf, hashing_tf2, idf2, label_indexer, feature_assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_eval(model, test_data, description=\"\", verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluates a machine learning model's accuracy on test data.\n",
    "\n",
    "    Args:\n",
    "        model: The trained Spark ML model.\n",
    "        test_data (DataFrame): The test dataset.\n",
    "        description (str, optional): A description of the model for output. Defaults to \"\".\n",
    "        verbose (bool, optional): Enable verbose output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model.\n",
    "    \"\"\"\n",
    "    # Make predictions on test data\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Evaluate model accuracy\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    if verbose:\n",
    "      print(f\"Evaluation of {description}. \\n\"+\n",
    "            f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b65ad2-c53e-438c-878e-e5b2b416302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_forest(train_data, pre_pipe):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest classification model.\n",
    "\n",
    "    Args:\n",
    "        train_data (DataFrame): The training dataset.\n",
    "        pre_pipe (list): List of pre-processing stages.\n",
    "\n",
    "    Returns:\n",
    "        PipelineModel: The trained Random Forest model.\n",
    "    \"\"\"\n",
    "    # Define the Random Forest classifier\n",
    "    classifier = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "\n",
    "    # Create a new pipeline using Random Forest\n",
    "    pipeline = Pipeline(stages= pre_pipe + [classifier])\n",
    "\n",
    "    # Train the model\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Save the trained model\n",
    "    #model.save(\"hdfs://192.168.2.156:9000/data/reddit/model/reddit_text_classifier_rf\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d768be0-7041-48a0-9126-10b7857b53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression(train_data, pre_pipe):\n",
    "    \"\"\"\n",
    "    Trains a Logistic Regression classification model.\n",
    "\n",
    "    Args:\n",
    "        train_data (DataFrame): The training dataset.\n",
    "        pre_pipe (list): List of pre-processing stages.\n",
    "\n",
    "    Returns:\n",
    "        PipelineModel: The trained Logistic Regression model.\n",
    "    \"\"\"\n",
    "    # Define the classification model\n",
    "    classifier = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "    # Create a new pipeline using Logistic Regression\n",
    "    pipeline = Pipeline(stages= pre_pipe + [classifier])\n",
    "\n",
    "    # Train the model\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Save the trained model\n",
    "    # model.save(\"hdfs://192.168.2.156:9000/data/reddit/model/reddit_text_classifier\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(file_path, fileSize, no_samples, executor_cores, executor_memory, execution_time, accuracy_rf, accuracy_lr):\n",
    "    \"\"\"\n",
    "    Prints performance and evaluation results.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path of the input file.\n",
    "        fileSize (float): Size of the input file in GB.\n",
    "        no_samples (int): Number of samples processed.\n",
    "        executor_cores (int): Number of executor cores.\n",
    "        executor_memory (str): Executor memory configuration.\n",
    "        execution_time (float): Total execution time in seconds.\n",
    "        accuracy_rf (float): Accuracy of the Random Forest model.\n",
    "        accuracy_lr (float): Accuracy of the Logistic Regression model.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Spark Processing and Model Evaluation Results\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(f\"File Path:        {file_path}\")\n",
    "    print(f\"File Size:        {fileSize:.2f} GB\")\n",
    "    print(f\"No samples:       {no_samples}\")\n",
    "    print(f\"Executor Cores:   {executor_cores}\")\n",
    "    print(f\"Executor Memory:  {executor_memory}\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Performance Metrics:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(f\"Execution Time:   {execution_time:.2f} seconds\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Model Accuracy:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(f\"Random Forest Accuracy:     {accuracy_rf:.4f}\")\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy_lr:.4f}\")\n",
    "\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "61f5dcb2-ca24-4745-9110-884f1f5f5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path = \"hdfs://192.168.2.156:9000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b169bdc0-8af5-4948-9c18-1f438006432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time: 16.5790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest time: 192.5081\n",
      "--------------------------------------------------------------------------------\n",
      "Spark Processing and Model Evaluation Results\n",
      "--------------------------------------------------------------------------------\n",
      "File Path:        /data/reddit/reddit_50k.json\n",
      "File Size:        0.37 GB\n",
      "No samples:       49817\n",
      "Executor Cores:   2\n",
      "Executor Memory:  4g\n",
      "--------------------------------------------------------------------------------\n",
      "Performance Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Execution Time:   229.44 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Model Accuracy:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest Accuracy:     0.2331\n",
      "Logistic Regression Accuracy: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Run: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time: 15.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest time: 191.6205\n",
      "--------------------------------------------------------------------------------\n",
      "Spark Processing and Model Evaluation Results\n",
      "--------------------------------------------------------------------------------\n",
      "File Path:        /data/reddit/reddit_50k.json\n",
      "File Size:        0.37 GB\n",
      "No samples:       49817\n",
      "Executor Cores:   2\n",
      "Executor Memory:  4g\n",
      "--------------------------------------------------------------------------------\n",
      "Performance Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Execution Time:   227.44 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Model Accuracy:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest Accuracy:     0.2331\n",
      "Logistic Regression Accuracy: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Run: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time: 15.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest time: 189.7341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Spark Processing and Model Evaluation Results\n",
      "--------------------------------------------------------------------------------\n",
      "File Path:        /data/reddit/reddit_50k.json\n",
      "File Size:        0.37 GB\n",
      "No samples:       49817\n",
      "Executor Cores:   2\n",
      "Executor Memory:  4g\n",
      "--------------------------------------------------------------------------------\n",
      "Performance Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Execution Time:   226.42 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Model Accuracy:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest Accuracy:     0.2331\n",
      "Logistic Regression Accuracy: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Run: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time: 16.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest time: 191.2340\n",
      "--------------------------------------------------------------------------------\n",
      "Spark Processing and Model Evaluation Results\n",
      "--------------------------------------------------------------------------------\n",
      "File Path:        /data/reddit/reddit_50k.json\n",
      "File Size:        0.37 GB\n",
      "No samples:       49817\n",
      "Executor Cores:   2\n",
      "Executor Memory:  4g\n",
      "--------------------------------------------------------------------------------\n",
      "Performance Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Execution Time:   227.42 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Model Accuracy:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest Accuracy:     0.2331\n",
      "Logistic Regression Accuracy: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Run: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time: 16.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest time: 192.4618\n",
      "--------------------------------------------------------------------------------\n",
      "Spark Processing and Model Evaluation Results\n",
      "--------------------------------------------------------------------------------\n",
      "File Path:        /data/reddit/reddit_50k.json\n",
      "File Size:        0.37 GB\n",
      "No samples:       49817\n",
      "Executor Cores:   2\n",
      "Executor Memory:  4g\n",
      "--------------------------------------------------------------------------------\n",
      "Performance Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Execution Time:   229.44 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Model Accuracy:\n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest Accuracy:     0.2331\n",
      "Logistic Regression Accuracy: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "49817.0\n",
      "[49817. 49817. 49817. 49817. 49817.]\n",
      "228.0314193725586\n",
      "[229.43670726 227.43915629 226.4240737  227.41858935 229.43857026]\n",
      "0.23313008130081297\n",
      "[0.23313008 0.23313008 0.23313008 0.23313008 0.23313008]\n",
      "0.0\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "verbose=False\n",
    "file_path = \"/data/reddit/reddit_50k.json\"\n",
    "reddit_50_samples = np.zeros(5)\n",
    "reddit_50_time    = np.zeros(5)\n",
    "reddit_50_rf_acc  = np.zeros(5)\n",
    "reddit_50_lr_acc  = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Run: {i}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    spark_session, spark_context, fileSize = build_spark_session(hdfs_path, file_path, verbose=verbose)\n",
    "    df = load_data(spark_session, hdfs_path, file_path, fileSize, verbose=verbose)\n",
    "    train_data, test_data, no_samples = filter_and_split_data(df, verbose=verbose)\n",
    "    pre_time = time.time()\n",
    "    pre_time = pre_time - start_time\n",
    "    print(f\"Pre-processing time: {pre_time:.4f}\")\n",
    "\n",
    "    pre_pipe = pre_processing_pipe()\n",
    "    model_rf = random_forest(train_data, pre_pipe)\n",
    "    rf_time  = time.time()\n",
    "    rf_time  = rf_time - start_time - pre_time\n",
    "    accuracy_rf = model_eval(model_rf, test_data, description=\"Random forest classifier\")\n",
    "    print(f\"Random forest time: {rf_time:.4f}\")\n",
    "\n",
    "    \"\"\" pre_pipe = pre_processing_pipe()\n",
    "    model_lr = logistic_regression(train_data, pre_pipe)\n",
    "    lr_time  = time.time()\n",
    "    lr_time  = lr_time - start_time - rf_time\n",
    "    accuracy_lr = model_eval(model_lr, test_data, description=\"Logistic regression classifier\")\n",
    "    print(f\"Logistic regression time: {lr_time:.4f}\") \"\"\"\n",
    "    accuracy_lr = 0\n",
    "\n",
    "    executor_cores = spark_session.conf.get(\"spark.executor.cores\")\n",
    "    executor_memory = spark_session.conf.get(\"spark.executor.memory\")\n",
    "\n",
    "    spark_context.stop()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    reddit_50_samples[i] = no_samples\n",
    "    reddit_50_time[i]    = execution_time\n",
    "    reddit_50_rf_acc[i]  = accuracy_rf\n",
    "    reddit_50_lr_acc[i]  = accuracy_lr\n",
    "\n",
    "    \n",
    "    print_results(file_path=file_path, fileSize=bytes_to_gb(fileSize), no_samples=no_samples, executor_cores=executor_cores, \n",
    "                executor_memory=executor_memory, execution_time=execution_time, \n",
    "                accuracy_rf=accuracy_rf, accuracy_lr=accuracy_lr)\n",
    "            \n",
    "print(reddit_50_samples.mean())\n",
    "print(reddit_50_samples)\n",
    "\n",
    "print(reddit_50_time.mean())\n",
    "print(reddit_50_time)\n",
    "\n",
    "print(reddit_50_rf_acc.mean())\n",
    "print(reddit_50_rf_acc)\n",
    "\n",
    "print(reddit_50_lr_acc.mean())\n",
    "print(reddit_50_lr_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9b65ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time: 79.9350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o19655.evaluate.\n: java.lang.OutOfMemoryError: Java heap space\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[261], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m rf_time  \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m rf_time  \u001b[38;5;241m=\u001b[39m rf_time \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m pre_time\n\u001b[0;32m---> 23\u001b[0m accuracy_rf \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandom forest classifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom forest time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" pre_pipe = pre_processing_pipe()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mmodel_lr = logistic_regression(train_data, pre_pipe)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mlr_time  = time.time()\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mlr_time  = lr_time - start_time - rf_time\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03maccuracy_lr = model_eval(model_lr, test_data, description=\"Logistic regression classifier\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mprint(f\"Logistic regression time: {lr_time:.4f}\") \"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[255], line 8\u001b[0m, in \u001b[0;36mmodel_eval\u001b[0;34m(model, test_data, description, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate model accuracy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m MulticlassClassificationEvaluator(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, metricName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o19655.evaluate.\n: java.lang.OutOfMemoryError: Java heap space\n"
     ]
    }
   ],
   "source": [
    "verbose=False\n",
    "file_path = \"/data/reddit/reddit_100k.json\"\n",
    "reddit_100_samples = np.zeros(5)\n",
    "reddit_100_time    = np.zeros(5)\n",
    "reddit_100_rf_acc  = np.zeros(5)\n",
    "reddit_100_lr_acc  = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Run: {i}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    spark_session, spark_context, fileSize = build_spark_session(hdfs_path, file_path, verbose=verbose)\n",
    "    df = load_data(spark_session, hdfs_path, file_path, fileSize, verbose=verbose)\n",
    "    train_data, test_data, no_samples = filter_and_split_data(df, verbose=verbose)\n",
    "    pre_time = time.time()\n",
    "    pre_time = pre_time - start_time\n",
    "    print(f\"Pre-processing time: {pre_time:.4f}\")\n",
    "\n",
    "    pre_pipe = pre_processing_pipe()\n",
    "    model_rf = random_forest(train_data, pre_pipe)\n",
    "    rf_time  = time.time()\n",
    "    rf_time  = rf_time - start_time - pre_time\n",
    "    accuracy_rf = model_eval(model_rf, test_data, description=\"Random forest classifier\")\n",
    "    print(f\"Random forest time: {rf_time:.4f}\")\n",
    "\n",
    "    \"\"\" pre_pipe = pre_processing_pipe()\n",
    "    model_lr = logistic_regression(train_data, pre_pipe)\n",
    "    lr_time  = time.time()\n",
    "    lr_time  = lr_time - start_time - rf_time\n",
    "    accuracy_lr = model_eval(model_lr, test_data, description=\"Logistic regression classifier\")\n",
    "    print(f\"Logistic regression time: {lr_time:.4f}\") \"\"\"\n",
    "    accuracy_lr = 0\n",
    "\n",
    "    executor_cores = spark_session.conf.get(\"spark.executor.cores\")\n",
    "    executor_memory = spark_session.conf.get(\"spark.executor.memory\")\n",
    "    spark_context.stop()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    reddit_50_samples[i] = no_samples\n",
    "    reddit_50_time[i]    = execution_time\n",
    "    reddit_50_rf_acc[i]  = accuracy_rf\n",
    "    reddit_50_lr_acc[i]  = accuracy_lr\n",
    "\n",
    "    print_results(file_path=file_path, fileSize=bytes_to_gb(fileSize), no_samples=no_samples, executor_cores=executor_cores, \n",
    "                executor_memory=executor_memory, execution_time=execution_time, \n",
    "                accuracy_rf=accuracy_rf, accuracy_lr=accuracy_lr)\n",
    "            \n",
    "print(reddit_100_samples.mean())\n",
    "print(reddit_100_samples)\n",
    "\n",
    "print(reddit_100_time.mean())\n",
    "print(reddit_100_time)\n",
    "\n",
    "print(reddit_100_rf_acc.mean())\n",
    "print(reddit_100_rf_acc)\n",
    "\n",
    "print(reddit_100_lr_acc.mean())\n",
    "print(reddit_100_lr_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "file_path = \"/data/reddit/reddit_200k.json\"\n",
    "reddit_200_samples = np.zeros(5)\n",
    "reddit_200_time    = np.zeros(5)\n",
    "reddit_200_rf_acc  = np.zeros(5)\n",
    "reddit_200_lr_acc  = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Run: {i}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    spark_session, spark_context, fileSize = build_spark_session(hdfs_path, file_path, verbose=verbose)\n",
    "    df = load_data(spark_session, hdfs_path, file_path, fileSize, verbose=verbose)\n",
    "    train_data, test_data, no_samples = filter_and_split_data(df, verbose=verbose)\n",
    "    pre_time = time.time()\n",
    "    pre_time = pre_time - start_time\n",
    "    print(f\"Pre-processing time: {pre_time:.4f}\")\n",
    "\n",
    "    pre_pipe = pre_processing_pipe()\n",
    "    model_rf = random_forest(train_data, pre_pipe)\n",
    "    rf_time  = time.time()\n",
    "    rf_time  = rf_time - start_time - pre_time\n",
    "    accuracy_rf = model_eval(model_rf, test_data, description=\"Random forest classifier\")\n",
    "    print(f\"Random forest time: {rf_time:.4f}\")\n",
    "\n",
    "    \"\"\" pre_pipe = pre_processing_pipe()\n",
    "    model_lr = logistic_regression(train_data, pre_pipe)\n",
    "    lr_time  = time.time()\n",
    "    lr_time  = lr_time - start_time - rf_time\n",
    "    accuracy_lr = model_eval(model_lr, test_data, description=\"Logistic regression classifier\")\n",
    "    print(f\"Logistic regression time: {lr_time:.4f}\") \"\"\"\n",
    "    accuracy_lr = 0\n",
    "\n",
    "    executor_cores = spark_session.conf.get(\"spark.executor.cores\")\n",
    "    executor_memory = spark_session.conf.get(\"spark.executor.memory\")\n",
    "    spark_context.stop()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    reddit_50_samples[i] = no_samples\n",
    "    reddit_50_time[i]    = execution_time\n",
    "    reddit_50_rf_acc[i]  = accuracy_rf\n",
    "    reddit_50_lr_acc[i]  = accuracy_lr\n",
    "\n",
    "    print_results(file_path=file_path, fileSize=bytes_to_gb(fileSize), no_samples=no_samples, executor_cores=executor_cores, \n",
    "                executor_memory=executor_memory, execution_time=execution_time, \n",
    "                accuracy_rf=accuracy_rf, accuracy_lr=accuracy_lr)\n",
    "            \n",
    "print(reddit_200_samples.mean())\n",
    "print(reddit_200_samples)\n",
    "\n",
    "print(reddit_200_time.mean())\n",
    "print(reddit_200_time)\n",
    "\n",
    "print(reddit_200_rf_acc.mean())\n",
    "print(reddit_200_rf_acc)\n",
    "\n",
    "print(reddit_200_lr_acc.mean())\n",
    "print(reddit_200_lr_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2fda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "file_path = \"/data/reddit/reddit_500k.json\"\n",
    "reddit_500_samples = np.zeros(5)\n",
    "reddit_500_time    = np.zeros(5)\n",
    "reddit_500_rf_acc  = np.zeros(5)\n",
    "reddit_500_lr_acc  = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Run: {i}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    spark_session, spark_context, fileSize = build_spark_session(hdfs_path, file_path, verbose=verbose)\n",
    "    df = load_data(spark_session, hdfs_path, file_path, fileSize, verbose=verbose)\n",
    "    train_data, test_data, no_samples = filter_and_split_data(df, verbose=verbose)\n",
    "    pre_time = time.time()\n",
    "    pre_time = pre_time - start_time\n",
    "    print(f\"Pre-processing time: {pre_time:.4f}\")\n",
    "\n",
    "    pre_pipe = pre_processing_pipe()\n",
    "    model_rf = random_forest(train_data, pre_pipe)\n",
    "    rf_time  = time.time()\n",
    "    rf_time  = rf_time - start_time - pre_time\n",
    "    accuracy_rf = model_eval(model_rf, test_data, description=\"Random forest classifier\")\n",
    "    print(f\"Random forest time: {rf_time:.4f}\")\n",
    "\n",
    "    \"\"\" pre_pipe = pre_processing_pipe()\n",
    "    model_lr = logistic_regression(train_data, pre_pipe)\n",
    "    lr_time  = time.time()\n",
    "    lr_time  = lr_time - start_time - rf_time\n",
    "    accuracy_lr = model_eval(model_lr, test_data, description=\"Logistic regression classifier\")\n",
    "    print(f\"Logistic regression time: {lr_time:.4f}\") \"\"\"\n",
    "    accuracy_lr = 0\n",
    "\n",
    "    executor_cores = spark_session.conf.get(\"spark.executor.cores\")\n",
    "    executor_memory = spark_session.conf.get(\"spark.executor.memory\")\n",
    "    spark_context.stop()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    reddit_50_samples[i] = no_samples\n",
    "    reddit_50_time[i]    = execution_time\n",
    "    reddit_50_rf_acc[i]  = accuracy_rf\n",
    "    reddit_50_lr_acc[i]  = accuracy_lr\n",
    "\n",
    "    print_results(file_path=file_path, fileSize=bytes_to_gb(fileSize), no_samples=no_samples, executor_cores=executor_cores, \n",
    "                executor_memory=executor_memory, execution_time=execution_time, \n",
    "                accuracy_rf=accuracy_rf, accuracy_lr=accuracy_lr)\n",
    "            \n",
    "print(reddit_500_samples.mean())\n",
    "print(reddit_500_samples)\n",
    "\n",
    "print(reddit_500_time.mean())\n",
    "print(reddit_500_time)\n",
    "\n",
    "print(reddit_500_rf_acc.mean())\n",
    "print(reddit_500_rf_acc)\n",
    "\n",
    "print(reddit_500_lr_acc.mean())\n",
    "print(reddit_500_lr_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "file_path = \"/data/reddit/corpus-webis-tldr-17.json\"\n",
    "reddit_full_samples = np.zeros(5)\n",
    "reddit_full_time    = np.zeros(5)\n",
    "reddit_full_rf_acc  = np.zeros(5)\n",
    "reddit_full_lr_acc  = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Run: {i}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    spark_session, spark_context, fileSize = build_spark_session(hdfs_path, file_path, verbose=verbose)\n",
    "    df = load_data(spark_session, hdfs_path, file_path, fileSize, verbose=verbose)\n",
    "    train_data, test_data, no_samples = filter_and_split_data(df, verbose=verbose)\n",
    "    pre_time = time.time()\n",
    "    pre_time = pre_time - start_time\n",
    "    print(f\"Pre-processing time: {pre_time:.4f}\")\n",
    "\n",
    "    pre_pipe = pre_processing_pipe()\n",
    "    model_rf = random_forest(train_data, pre_pipe)\n",
    "    rf_time  = time.time()\n",
    "    rf_time  = rf_time - start_time - pre_time\n",
    "    accuracy_rf = model_eval(model_rf, test_data, description=\"Random forest classifier\")\n",
    "    print(f\"Random forest time: {rf_time:.4f}\")\n",
    "\n",
    "    \"\"\" pre_pipe = pre_processing_pipe()\n",
    "    model_lr = logistic_regression(train_data, pre_pipe)\n",
    "    lr_time  = time.time()\n",
    "    lr_time  = lr_time - start_time - rf_time\n",
    "    accuracy_lr = model_eval(model_lr, test_data, description=\"Logistic regression classifier\")\n",
    "    print(f\"Logistic regression time: {lr_time:.4f}\") \"\"\"\n",
    "    accuracy_lr = 0\n",
    "\n",
    "    executor_cores = spark_session.conf.get(\"spark.executor.cores\")\n",
    "    executor_memory = spark_session.conf.get(\"spark.executor.memory\")\n",
    "    spark_context.stop()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    reddit_50_samples[i] = no_samples\n",
    "    reddit_50_time[i]    = execution_time\n",
    "    reddit_50_rf_acc[i]  = accuracy_rf\n",
    "    reddit_50_lr_acc[i]  = accuracy_lr\n",
    "\n",
    "    print_results(file_path=file_path, fileSize=bytes_to_gb(fileSize), no_samples=no_samples, executor_cores=executor_cores, \n",
    "                executor_memory=executor_memory, execution_time=execution_time, \n",
    "                accuracy_rf=accuracy_rf, accuracy_lr=accuracy_lr)\n",
    "            \n",
    "print(reddit_full_samples.mean())\n",
    "print(reddit_full_samples)\n",
    "\n",
    "print(reddit_full_time.mean())\n",
    "print(reddit_full_time)\n",
    "\n",
    "print(reddit_full_rf_acc.mean())\n",
    "print(reddit_full_rf_acc)\n",
    "\n",
    "print(reddit_full_lr_acc.mean())\n",
    "print(reddit_full_lr_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7092dd2b-e265-41fe-a832-38c8d38d8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c12129-08fd-48d2-bdac-983d5af5c9b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652336a3-1a25-4616-81ce-ac2cd1e1874b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7ba16-375f-4236-bbee-1776bc00f0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
